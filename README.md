# Neo4j + LLM

## Knowledge Graphs (KGs)

Knowledge graphs are a specific implementation of a Graph Database, where information is captured and integrated from many different sources, representing the inherent knowledge of a particular domain.

They provide a structured way to represent entities, their attributes, and relationships, allowing for a comprehensive and interconnected understanding of the information within that domain.

This integration from diverse sources gives knowledge graphs a more holistic view and facilitates complex queries, analytics, and insights.

Knowledge graphs are tailored for semantic search, data retrieval, reasoning, and data amalgamation, frequently powering search engines, AI, and research.

Knowledge graphs typically lean on ontologies, offering structured concepts within a domain and their interrelations. Conversely, while Neo4j can engage with ontologies and offers schema constraints, its standard graphs may not consistently utilize or demand structured semantic frameworks.

Neo4j has a great primer youtube playlist:
<https://www.youtube.com/playlist?list=PL9Hl4pk2FsvX-5QPvwChB-ni_mFF97rCE>

## Generative AI and LLMs

Generative AI is a class of algorithms and models that can generate new content, such as images, text, or even music, in response to user prompting, based on patterns and examples from existing data.

Large Language Models, most commonly referred to as LLMs, learn the underlying structure and distribution of the data and can then generate new samples that resemble the original data.

Generative AI models can generate highly realistic and creative outputs by leveraging the power of machine learning and deep learning techniques. LLMs are trained on vast amounts of text data to understand and generate human-like text.

They can answer questions, create content, and assist with various linguistic tasks by leveraging patterns learned from the data.

### Interacting with an LLM

The response generated by an LLM is a probabilistic continuation of the instructions it receives. The LLM provides the most likely response based on the patterns it has learned from its training data.

To get an LLM to perform a task, you provide a prompt, a piece of text that should specify your requirements and provide clear instructions on how to respond. Precision in the task description, potentially combined with examples or context, ensures that the model understands the intent and produces relevant and accurate outputs.

An example prompt may be a simple question.

>What is the capital of Japan?

Or, it could be more descriptive. For example:

>Produce a brief list of talking points exploring the subject of Knowledge Graphs and how they relate to LLMs.
>The content should be targeted at Developers and Data Scientists.
>Your readers may have English as a second language, so use simple terms and avoid colloquialisms.
>Avoid Jargon at all costs.
>Return the results as a list of JSON strings containing content formatted in Markdown.

The LLM will interpret these instructions and return a response based on the patterns it has learned from its training data.
